{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a11d5e",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation\n",
    "`Query -> Search a Database -> Relevant Documents -> Send to LLM -> Contextually Relevant Answer` <br/>\n",
    "\n",
    "Complexity from decisions based on:\n",
    "- Chunking.\n",
    "- Databases.\n",
    "- Preprocessing query.\n",
    "- Postprocessing results.\n",
    "- Semantic vs Keywords.\n",
    "- Hypothetical searches.\n",
    "- Multi-hop retrieval.\n",
    "- Agentic retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ae69",
   "metadata": {},
   "source": [
    "#### Multi-Hop Retrieval\n",
    "`Question -> LM <-> Hybrid Search from DB` <br/>\n",
    "`Context -> LM <-> DB` <br/>\n",
    "`Context -> LM -> Answer` <br/>\n",
    "\n",
    "#### Hybrid HyDE Search\n",
    "`Question -> HyDE LM -> (Semantic Query -> Embedding Search) + (BM-25 Query -> BM-25 Search) -> Reciprocal Rank Fusion`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f4530",
   "metadata": {},
   "source": [
    "### Setup Jokes DB\n",
    "<a href=\"https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes\">Dataset link.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4880984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haider\\Desktop\\code\\Context-Engineering\\with DSPy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def embed_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = model_output.last_hidden_state[:,0,:].numpy()\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b6b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path('embeddings.npy').exists():\n",
    "    data = pd.read_csv('shortjokes.csv')\n",
    "    jokes = data['Joke'].values\n",
    "    jokes = jokes[:5000]\n",
    "    \n",
    "    batch_size = 512\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(jokes), batch_size), desc='Generating embeddings'):\n",
    "        batch_texts = jokes[i:i+batch_size].tolist()\n",
    "        batch_embeddings = embed_texts(batch_texts)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    print(f'Total embeddings: {len(embeddings)}')\n",
    "    np.save('embeddings.npy', embeddings)\n",
    "    with open('jokes.txt', 'w') as f:\n",
    "        for joke in jokes:\n",
    "            f.write(joke+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d80096",
   "metadata": {},
   "source": [
    "### Basic Nearest-Neighbors RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b12b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicEmbeddingsRAG:\n",
    "    def __init__(self, texts, embeddings):\n",
    "        self.texts = texts\n",
    "        self.embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        query_emb = embed_texts([query])\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        # cosine similarity\n",
    "        # only need dot-product as the embeddings are already normalized\n",
    "        similarity = np.dot(query_emb, self.embeddings.T).flatten()\n",
    "        \n",
    "        topk_idxs = np.argpartition(similarity, -k)[-k:]\n",
    "        topk_idxs = sorted(topk_idxs, key=lambda x: similarity[x],\n",
    "                           reverse=True)\n",
    "        \n",
    "        return [self.texts[i] for i in topk_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a595edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.042990922927856445\n",
      "[\"The best joke you'll never hear\", 'Meet the parents', 'Hire The Pretty Blonde', 'Just one time I wanna see The Bachelor get a cold sore', 'What do you call a bald porcupine? Pointless!', 'pull my upvote', \"My life That's the joke.\", 'What do you call corn with a sense of humor? Laughing stalk', 'What do you call a bald porcupine? Pointless.', 'Velcro. What a rip off!']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = 'Laugh'\n",
    "with open('jokes.txt', 'r') as f:\n",
    "    jokes = [l.strip() for l in f.readlines()]\n",
    "embs = np.load('embeddings.npy')\n",
    "\n",
    "basic_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "\n",
    "start = time.time()\n",
    "nearest = basic_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time: {end - start}')\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b4f59",
   "metadata": {},
   "source": [
    "### Approximate Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039b486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "class AnnoyRAG:\n",
    "    def __init__(self, texts, embeddings, n_trees=10):\n",
    "        self.texts = texts\n",
    "        self.emb_dim = embeddings.shape[1]\n",
    "        self.index = AnnoyIndex(self.emb_dim, 'angular')\n",
    "        \n",
    "        normalized_embs = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        for i, vec in enumerate(normalized_embs):\n",
    "            self.index.add_item(i, vec)\n",
    "        self.index.build(n_trees)\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        query_emb = embed_texts([query])\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        nearest_idxs = self.index.get_nns_by_vector(query_emb[0], k)\n",
    "        return [self.texts[i] for i in nearest_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8e3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Basic: 0.018012285232543945\n",
      "Time for Annoy: 0.01598978042602539\n",
      "['What comes before OP? QWERTYUI', 'Be alert! The world needs more lerts.', '\"Blinding Nemo\" #BPMovies', 'How do you call a beautiful feminist? An oxymoron', 'Who is the king of the pencil case? The Ruler', 'Political Joke The Economy', '\"I see people.\" - The Fifth Sense', \"What comes after America? Bmerica. I'll see myself out\", 'Genderfluid? I just call that semen', 'Meet the parents']\n",
      "['Be alert! The world needs more lerts.', '\"Blinding Nemo\" #BPMovies', 'How do you call a beautiful feminist? An oxymoron', 'Political Joke The Economy', '\"I see people.\" - The Fifth Sense', 'Genderfluid? I just call that semen', 'Meet the parents', 'Velcro. What a rip off!', 'What is it that is yours , but others use it more than you ? Your name', \"What do you call someone incapable of eating people? A can't-ibal\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'AI is rogue'\n",
    "\n",
    "basic_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "annoy_rag = AnnoyRAG(jokes, embs)\n",
    "\n",
    "start = time.time()\n",
    "nearest_basic = basic_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time for Basic: {end - start}')\n",
    "\n",
    "start = time.time()\n",
    "nearest_annoy = annoy_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time for Annoy: {end - start}')\n",
    "\n",
    "print(nearest_basic)\n",
    "print(nearest_annoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17426a0b",
   "metadata": {},
   "source": [
    "### BM-25 Retrieval\n",
    "- Previous approaches are semantic-based.\n",
    "  - Uses embeddings.\n",
    "  - Captures overall semantic correlation.\n",
    "  - May mess up direct matches.\n",
    "- BM25 is keyword-based retrieval.\n",
    "  - Direct term-frequency matching.\n",
    "  - Can't capture synonyms, only direct matches.\n",
    "- E.g. Usecase: Searching for a specific model in a refrigerator manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307b4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        self.bm25 = BM25Okapi([t.split(' ') for t in texts])  # tokenize by splitting on space\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        tokenized = query.split(' ')\n",
    "        topk_docs = self.bm25.get_top_n(tokenized, self.texts, n=k)\n",
    "        return topk_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683ef719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.0019989013671875\n",
      "['What Cell Phone Company does Usain Bolt use? Sprint', 'Ever since the news came out about Samsung.... Their phones have been blowing up.', \"I bet kangaroos get tired of holding all of their friend's keys and cell phones while they're at the beach.\", 'I become instantly beautiful when I put on my sunglasses. -Every girl, ever.', 'What did the ruler gain a reputation for while campaigning? Straight talk.', 'How do you fit 4 gays on one barstool? Flip it over!', 'I want my tombstone to read \"Free WiFi\" so people would visit more often', 'You ever notice that the most dangerous thing about marijuana is getting caught with it?', 'What did Arnold Schwarzenegger say at the abortion clinic? Hasta last vista, baby.', 'Sucks that these Crest strips only come in white']\n"
     ]
    }
   ],
   "source": [
    "query = 'Cell phones'\n",
    "\n",
    "bm25_retriever = BM25Retriever(jokes)\n",
    "\n",
    "start = time.time()\n",
    "nearest_bm25 = bm25_retriever.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time: {end-start}')\n",
    "print(nearest_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9400e",
   "metadata": {},
   "source": [
    "### Combining Both Approaches\n",
    "#### Reciprocal Rank Fusion\n",
    "- Classic search engine technique.\n",
    "- Combines multiple ranked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a46c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(ranked_lists, k=60):\n",
    "    scores = {}\n",
    "    # calculate RRF scores\n",
    "    for ranked_list in ranked_lists:\n",
    "        for rank, doc in enumerate(ranked_list):\n",
    "            if doc not in scores:\n",
    "                scores[doc] = 0\n",
    "            scores[doc] += 1 / (k + rank + 1)\n",
    "    \n",
    "    docs = sorted(scores.keys(),\n",
    "                  key=lambda doc: scores[doc],\n",
    "                  reverse=True)\n",
    "    docs = docs[:k]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d946d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Results (0.0169s)\n",
      "\t1. Meet the parents\n",
      "\t2. South Africa\n",
      "\t3. pull my upvote\n",
      "\t4. Political Joke The Economy\n",
      "\t5. I have a joke to tell. Can you reddit?\n",
      "\t6. My life That's the joke.\n",
      "\t7. The best joke you'll never hear\n",
      "\t8. I like the sound of you not talking.\n",
      "\t9. Hire The Pretty Blonde\n",
      "\t10. I have a joke about Ebola You probably won't get it\n",
      "BM25 Results (0.0030s)\n",
      "\t1. What Cell Phone Company does Usain Bolt use? Sprint\n",
      "\t2. Ever since the news came out about Samsung.... Their phones have been blowing up.\n",
      "\t3. I bet kangaroos get tired of holding all of their friend's keys and cell phones while they're at the beach.\n",
      "\t4. I become instantly beautiful when I put on my sunglasses. -Every girl, ever.\n",
      "\t5. What did the ruler gain a reputation for while campaigning? Straight talk.\n",
      "\t6. How do you fit 4 gays on one barstool? Flip it over!\n",
      "\t7. I want my tombstone to read \"Free WiFi\" so people would visit more often\n",
      "\t8. You ever notice that the most dangerous thing about marijuana is getting caught with it?\n",
      "\t9. What did Arnold Schwarzenegger say at the abortion clinic? Hasta last vista, baby.\n",
      "\t10. Sucks that these Crest strips only come in white\n",
      "Fused and Re-ranked Results (Top 10)\n",
      "\t1. Meet the parents\n",
      "\t2. What Cell Phone Company does Usain Bolt use? Sprint\n",
      "\t3. South Africa\n",
      "\t4. Ever since the news came out about Samsung.... Their phones have been blowing up.\n",
      "\t5. pull my upvote\n",
      "\t6. I bet kangaroos get tired of holding all of their friend's keys and cell phones while they're at the beach.\n",
      "\t7. Political Joke The Economy\n",
      "\t8. I become instantly beautiful when I put on my sunglasses. -Every girl, ever.\n",
      "\t9. I have a joke to tell. Can you reddit?\n",
      "\t10. What did the ruler gain a reputation for while campaigning? Straight talk.\n"
     ]
    }
   ],
   "source": [
    "query = 'Cell phones'\n",
    "topk = 10\n",
    "\n",
    "vector_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "bm25_retriever = BM25Retriever(jokes)\n",
    "\n",
    "start = time.time()\n",
    "vector_results = vector_rag.get_nearest(query, k=topk)\n",
    "end = time.time()\n",
    "vector_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "bm25_results = bm25_retriever.get_nearest(query, k=topk)\n",
    "end = time.time()\n",
    "bm25_time = end - start\n",
    "\n",
    "print(f'Vector Results ({vector_time:.4f}s)')\n",
    "for i, res in enumerate(vector_results):\n",
    "    print(f'\\t{i+1}. {res}')\n",
    "\n",
    "print(f'BM25 Results ({bm25_time:.4f}s)')\n",
    "for i, res in enumerate(bm25_results):\n",
    "    print(f'\\t{i+1}. {res}')\n",
    "\n",
    "fused_results = reciprocal_rank_fusion([vector_results, bm25_results])\n",
    "print(f'Fused and Re-ranked Results (Top {topk})')\n",
    "for i, res in enumerate(fused_results[:topk]):\n",
    "    print(f'\\t{i+1}. {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920bc1d",
   "metadata": {},
   "source": [
    "### Multi-Hop HyDE\n",
    "- Separate queries for Semantic and Keyword searches for maximum flexibility.\n",
    "  - Semantic search is optimized for Cosine Similarity search.\n",
    "  - BM25 search is optimized for short, keyword-based queries.\n",
    "- Multi-hop gives the LLM more chances to tune the query for a better hit.\n",
    "  - Often paired with validation checks for stopping earlier.\n",
    "  - E.g. Checking if the answer is already retrieved in a Q/A system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eab82eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from typing import Optional, List\n",
    "\n",
    "class HypotheticalDoc(dspy.Signature):\n",
    "    \"\"\"Given a query, generate hypothetical documents to search a database of one-liner jokes.\"\"\"\n",
    "    query: str = dspy.InputField(desc='User wants to fetch jokes related to this topic.')\n",
    "    retrieved_jokes: Optional[List[str]] = dspy.InputField(desc='Jokes previously retrieved from the DB. Use these to further tune your search.')\n",
    "    hypothetical_bm25_query: str = dspy.OutputField(desc='Sentence to query to retrieve more jokes about the query from the DB.')\n",
    "    hypothetical_semantic_query: str = dspy.OutputField(desc='Sentence to search with Cosine Similarity.')\n",
    "\n",
    "class MultiHopeHyDESearch(dspy.Module):\n",
    "    def __init__(self, texts, embs, n_hops=3, k=10):\n",
    "        self.pred = dspy.ChainOfThought(HypotheticalDoc)\n",
    "        self.pred.set_lm(dspy.LM('gemini/gemini-2.5-flash-lite'))\n",
    "        \n",
    "        self.emb_retriever = BasicEmbeddingsRAG(texts, embs)\n",
    "        self.bm25_retriever = BM25Retriever(texts)\n",
    "        \n",
    "        self.n_hops = n_hops\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, query):\n",
    "        retrieved_jokes = []\n",
    "        all_jokes = []\n",
    "        for _ in range(self.n_hops):\n",
    "            new_query = self.pred(query=query, retrieved_jokes=retrieved_jokes)\n",
    "            print(new_query)\n",
    "            \n",
    "            emb_lists = self.emb_retriever.get_nearest(new_query.hypothetical_semantic_query)\n",
    "            bm25_lists = self.bm25_retriever.get_nearest(new_query.hypothetical_bm25_query)\n",
    "            retrieved_jokes = reciprocal_rank_fusion([emb_lists, bm25_lists], k=self.k)\n",
    "            all_jokes.extend(retrieved_jokes)\n",
    "        return dspy.Prediction(jokes=all_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07bd93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The user is asking for jokes about cell phones. Since no jokes have been retrieved yet, I should generate a broad BM25 query and a semantic query that captures the essence of cell phone jokes.',\n",
      "    hypothetical_bm25_query='cell phone jokes',\n",
      "    hypothetical_semantic_query='Jokes about mobile phones and their use.'\n",
      ")\n",
      "Prediction(\n",
      "    reasoning='The user is asking for jokes about cell phones. The retrieved jokes include one directly about cell phones (\"My cell phone is so nervous whenever I go to the countryside... ...it\\'s constantly on EDGE.\") and another that mentions cell phone providers (\"NEVER date someone that works for your cell phone provider. You\\'re welcome.\"). To find more jokes, I should focus on keywords related to cell phones, mobile phones, smartphones, and common cell phone-related scenarios or features.',\n",
      "    hypothetical_bm25_query='cell phone jokes, mobile phone humor, smartphone jokes, funny cell phone stories',\n",
      "    hypothetical_semantic_query='Jokes about the everyday use, features, and frustrations of cell phones and smartphones.'\n",
      ")\n",
      "Prediction(\n",
      "    reasoning='The user is asking for jokes about \"cell phones\". The retrieved jokes include one directly about cell phones (\"My cell phone is so nervous whenever I go to the countryside... ...it\\'s constantly on EDGE.\") and another that mentions cell phone providers. The other jokes are not related to cell phones. To find more relevant jokes, I should focus on keywords like \"cell phone\", \"phone\", \"mobile\", \"texting\", \"apps\", \"smartphone\", and related concepts.',\n",
      "    hypothetical_bm25_query='cell phone joke OR phone joke OR mobile joke OR smartphone joke OR texting joke',\n",
      "    hypothetical_semantic_query='Jokes about cell phones, smartphones, and mobile devices.'\n",
      ")\n",
      "['Inside jokes are bitterly resented by the homeless.', 'What kind of jokes do bad comedians tell their audience? Bad jokes.', \"NEVER date someone that works for your cell phone provider. You're welcome.\", \"Friends don't force friends to watch 'funny' YouTube videos.\", \"My cell phone is so nervous whenever I go to the countryside... ...it's constantly on EDGE.\", \"Friends don't force friends to watch 'funny' YouTube videos.\", \"NEVER date someone that works for your cell phone provider. You're welcome.\", 'What kind of jokes do bad comedians tell their audience? Bad jokes.', \"My cell phone is so nervous whenever I go to the countryside... ...it's constantly on EDGE.\", \"An introvert looks down at his own shoes. An extrovert looks at other people's shoes.\", \"Friends don't force friends to watch 'funny' YouTube videos.\", 'Most suitable joke for reddit [deleted]', \"An introvert looks down at his own shoes. An extrovert looks at other people's shoes.\", \"The best joke you'll never hear\", 'What kind of jokes do bad comedians tell their audience? Bad jokes.']\n"
     ]
    }
   ],
   "source": [
    "query = 'Cell phones'\n",
    "k = 5\n",
    "n_hops = 3\n",
    "\n",
    "hyde = MultiHopeHyDESearch(jokes, embs, n_hops, k)\n",
    "retrieved_jokes = hyde(query=query).jokes\n",
    "print(retrieved_jokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45f5c",
   "metadata": {},
   "source": [
    "### JokeGenerator Example\n",
    "`Query -> (Idea LM <-> WebSearch) -> Joke Idea -> (Joke LM <-> Joke DB) -> Joke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "with DSPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
