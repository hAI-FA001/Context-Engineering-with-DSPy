{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a11d5e",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation\n",
    "`Query -> Search a Database -> Relevant Documents -> Send to LLM -> Contextually Relevant Answer` <br/>\n",
    "\n",
    "Complexity from decisions based on:\n",
    "- Chunking.\n",
    "- Databases.\n",
    "- Preprocessing query.\n",
    "- Postprocessing results.\n",
    "- Semantic vs Keywords.\n",
    "- Hypothetical searches.\n",
    "- Multi-hop retrieval.\n",
    "- Agentic retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ae69",
   "metadata": {},
   "source": [
    "#### Multi-Hop Retrieval\n",
    "`Question -> LM <-> Hybrid Search from DB` <br/>\n",
    "`Context -> LM <-> DB` <br/>\n",
    "`Context -> LM -> Answer` <br/>\n",
    "\n",
    "#### Hybrid HyDE Search\n",
    "`Question -> HyDE LM -> (Semantic Query -> Embedding Search) + (BM-25 Query -> BM-25 Search) -> Reciprocal Rank Fusion`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f4530",
   "metadata": {},
   "source": [
    "### Setup Jokes DB\n",
    "<a href=\"https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes\">Dataset link.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def embed_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = model_output.last_hidden_state[:,0,:].numpy()\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b6b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 10/10 [01:45<00:00, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('shortjokes.csv')\n",
    "jokes = data['Joke'].values\n",
    "jokes = jokes[:5000]\n",
    "batch_size = 512\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(jokes), batch_size), desc='Generating embeddings'):\n",
    "    batch_texts = jokes[i:i+batch_size].tolist()\n",
    "    batch_embeddings = embed_texts(batch_texts)\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "\n",
    "embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "print(f'Total embeddings: {len(embeddings)}')\n",
    "np.save('embeddings.npy', embeddings)\n",
    "with open('jokes.txt', 'w') as f:\n",
    "    for joke in jokes:\n",
    "        f.write(joke+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45f5c",
   "metadata": {},
   "source": [
    "### JokeGenerator Example\n",
    "`Query -> (Idea LM <-> WebSearch) -> Joke Idea -> (Joke LM <-> Joke DB) -> Joke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "with DSPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
