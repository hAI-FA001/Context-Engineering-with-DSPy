{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a11d5e",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation\n",
    "`Query -> Search a Database -> Relevant Documents -> Send to LLM -> Contextually Relevant Answer` <br/>\n",
    "\n",
    "Complexity from decisions based on:\n",
    "- Chunking.\n",
    "- Databases.\n",
    "- Preprocessing query.\n",
    "- Postprocessing results.\n",
    "- Semantic vs Keywords.\n",
    "- Hypothetical searches.\n",
    "- Multi-hop retrieval.\n",
    "- Agentic retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ae69",
   "metadata": {},
   "source": [
    "#### Multi-Hop Retrieval\n",
    "`Question -> LM <-> Hybrid Search from DB` <br/>\n",
    "`Context -> LM <-> DB` <br/>\n",
    "`Context -> LM -> Answer` <br/>\n",
    "\n",
    "#### Hybrid HyDE Search\n",
    "`Question -> HyDE LM -> (Semantic Query -> Embedding Search) + (BM-25 Query -> BM-25 Search) -> Reciprocal Rank Fusion`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f4530",
   "metadata": {},
   "source": [
    "### Setup Jokes DB\n",
    "<a href=\"https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes\">Dataset link.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4880984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haider\\Desktop\\code\\Context-Engineering\\with DSPy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def embed_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = model_output.last_hidden_state[:,0,:].numpy()\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b6b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path('embeddings.npy').exists():\n",
    "    data = pd.read_csv('shortjokes.csv')\n",
    "    jokes = data['Joke'].values\n",
    "    jokes = jokes[:5000]\n",
    "    \n",
    "    batch_size = 512\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(jokes), batch_size), desc='Generating embeddings'):\n",
    "        batch_texts = jokes[i:i+batch_size].tolist()\n",
    "        batch_embeddings = embed_texts(batch_texts)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    print(f'Total embeddings: {len(embeddings)}')\n",
    "    np.save('embeddings.npy', embeddings)\n",
    "    with open('jokes.txt', 'w') as f:\n",
    "        for joke in jokes:\n",
    "            f.write(joke+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d80096",
   "metadata": {},
   "source": [
    "### Basic Nearest-Neighbors RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b12b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicEmbeddingsRAG:\n",
    "    def __init__(self, texts, embeddings):\n",
    "        self.texts = texts\n",
    "        self.embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        query_emb = embed_texts([query])\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        # cosine similarity\n",
    "        # only need dot-product as the embeddings are already normalized\n",
    "        similarity = np.dot(query_emb, self.embeddings.T).flatten()\n",
    "        \n",
    "        topk_idxs = np.argpartition(similarity, -k)[-k:]\n",
    "        topk_idxs = sorted(topk_idxs, key=lambda x: similarity[x],\n",
    "                           reverse=True)\n",
    "        \n",
    "        return [self.texts[i] for i in topk_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a595edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.042990922927856445\n",
      "[\"The best joke you'll never hear\", 'Meet the parents', 'Hire The Pretty Blonde', 'Just one time I wanna see The Bachelor get a cold sore', 'What do you call a bald porcupine? Pointless!', 'pull my upvote', \"My life That's the joke.\", 'What do you call corn with a sense of humor? Laughing stalk', 'What do you call a bald porcupine? Pointless.', 'Velcro. What a rip off!']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = 'Laugh'\n",
    "with open('jokes.txt', 'r') as f:\n",
    "    jokes = [l.strip() for l in f.readlines()]\n",
    "embs = np.load('embeddings.npy')\n",
    "\n",
    "basic_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "\n",
    "start = time.time()\n",
    "nearest = basic_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time: {end - start}')\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b4f59",
   "metadata": {},
   "source": [
    "### Approximate Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039b486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "class AnnoyRAG:\n",
    "    def __init__(self, texts, embeddings, n_trees=10):\n",
    "        self.texts = texts\n",
    "        self.emb_dim = embeddings.shape[1]\n",
    "        self.index = AnnoyIndex(self.emb_dim, 'angular')\n",
    "        \n",
    "        normalized_embs = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        for i, vec in enumerate(normalized_embs):\n",
    "            self.index.add_item(i, vec)\n",
    "        self.index.build(n_trees)\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        query_emb = embed_texts([query])\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        nearest_idxs = self.index.get_nns_by_vector(query_emb[0], k)\n",
    "        return [self.texts[i] for i in nearest_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8e3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Basic: 0.018929481506347656\n",
      "Time for Annoy: 0.015997886657714844\n",
      "['What comes before OP? QWERTYUI', 'Be alert! The world needs more lerts.', '\"Blinding Nemo\" #BPMovies', 'How do you call a beautiful feminist? An oxymoron', 'Who is the king of the pencil case? The Ruler', 'Political Joke The Economy', '\"I see people.\" - The Fifth Sense', \"What comes after America? Bmerica. I'll see myself out\", 'Genderfluid? I just call that semen', 'Meet the parents']\n",
      "['Be alert! The world needs more lerts.', '\"Blinding Nemo\" #BPMovies', 'How do you call a beautiful feminist? An oxymoron', 'Political Joke The Economy', '\"I see people.\" - The Fifth Sense', 'Genderfluid? I just call that semen', 'Meet the parents', 'Velcro. What a rip off!', 'What is it that is yours , but others use it more than you ? Your name', \"What do you call someone incapable of eating people? A can't-ibal\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'AI is rogue'\n",
    "\n",
    "with open('jokes.txt', 'r') as f:\n",
    "    jokes = [l.strip() for l in f.readlines()]\n",
    "embs = np.load('embeddings.npy')\n",
    "\n",
    "basic_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "annoy_rag = AnnoyRAG(jokes, embs)\n",
    "\n",
    "start = time.time()\n",
    "nearest_basic = basic_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time for Basic: {end - start}')\n",
    "\n",
    "start = time.time()\n",
    "nearest_annoy = annoy_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time for Annoy: {end - start}')\n",
    "\n",
    "print(nearest_basic)\n",
    "print(nearest_annoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17426a0b",
   "metadata": {},
   "source": [
    "### BM-25 Retrieval\n",
    "- Previous approaches are semantic-based.\n",
    "  - Uses embeddings.\n",
    "  - Captures overall semantic correlation.\n",
    "  - May mess up direct matches.\n",
    "- BM25 is keyword-based retrieval.\n",
    "  - Direct term-frequency matching.\n",
    "  - Can't capture synonyms, only direct matches.\n",
    "- E.g. Usecase: Searching for a specific model in a refrigerator manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307b4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        self.bm25 = BM25Okapi([t.split(' ') for t in texts])  # tokenize by splitting on space\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        tokenized = query.split(' ')\n",
    "        topk_docs = self.bm25.get_top_n(tokenized, self.texts, n=k)\n",
    "        return topk_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683ef719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.002000570297241211\n",
      "['What Cell Phone Company does Usain Bolt use? Sprint', 'Ever since the news came out about Samsung.... Their phones have been blowing up.', \"I bet kangaroos get tired of holding all of their friend's keys and cell phones while they're at the beach.\", 'I become instantly beautiful when I put on my sunglasses. -Every girl, ever.', 'What did the ruler gain a reputation for while campaigning? Straight talk.', 'How do you fit 4 gays on one barstool? Flip it over!', 'I want my tombstone to read \"Free WiFi\" so people would visit more often', 'You ever notice that the most dangerous thing about marijuana is getting caught with it?', 'What did Arnold Schwarzenegger say at the abortion clinic? Hasta last vista, baby.', 'Sucks that these Crest strips only come in white']\n"
     ]
    }
   ],
   "source": [
    "query = 'Cell phones'\n",
    "\n",
    "with open('jokes.txt', 'r') as f:\n",
    "    jokes = [l.strip() for l in f.readlines()]\n",
    "\n",
    "bm25_retriever = BM25Retriever(jokes)\n",
    "\n",
    "start = time.time()\n",
    "nearest_bm25 = bm25_retriever.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "print(f'Time: {end-start}')\n",
    "print(nearest_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45f5c",
   "metadata": {},
   "source": [
    "### JokeGenerator Example\n",
    "`Query -> (Idea LM <-> WebSearch) -> Joke Idea -> (Joke LM <-> Joke DB) -> Joke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "with DSPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
