{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a11d5e",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation\n",
    "`Query -> Search a Database -> Relevant Documents -> Send to LLM -> Contextually Relevant Answer` <br/>\n",
    "\n",
    "Complexity from decisions based on:\n",
    "- Chunking.\n",
    "- Databases.\n",
    "- Preprocessing query.\n",
    "- Postprocessing results.\n",
    "- Semantic vs Keywords.\n",
    "- Hypothetical searches.\n",
    "- Multi-hop retrieval.\n",
    "- Agentic retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758ae69",
   "metadata": {},
   "source": [
    "#### Multi-Hop Retrieval\n",
    "`Question -> LM <-> Hybrid Search from DB` <br/>\n",
    "`Context -> LM <-> DB` <br/>\n",
    "`Context -> LM -> Answer` <br/>\n",
    "\n",
    "#### Hybrid HyDE Search\n",
    "`Question -> HyDE LM -> (Semantic Query -> Embedding Search) + (BM-25 Query -> BM-25 Search) -> Reciprocal Rank Fusion`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f4530",
   "metadata": {},
   "source": [
    "### Setup Jokes DB\n",
    "<a href=\"https://www.kaggle.com/datasets/abhinavmoudgil95/short-jokes\">Dataset link.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def embed_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = model_output.last_hidden_state[:,0,:].numpy()\n",
    "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b6b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 10/10 [01:45<00:00, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('shortjokes.csv')\n",
    "jokes = data['Joke'].values\n",
    "jokes = jokes[:5000]\n",
    "batch_size = 512\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(jokes), batch_size), desc='Generating embeddings'):\n",
    "    batch_texts = jokes[i:i+batch_size].tolist()\n",
    "    batch_embeddings = embed_texts(batch_texts)\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "\n",
    "embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "print(f'Total embeddings: {len(embeddings)}')\n",
    "np.save('embeddings.npy', embeddings)\n",
    "with open('jokes.txt', 'w') as f:\n",
    "    for joke in jokes:\n",
    "        f.write(joke+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b12b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicEmbeddingsRAG:\n",
    "    def __init__(self, texts, embeddings):\n",
    "        self.texts = texts\n",
    "        self.embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    def get_nearest(self, query: str, k: int = 10):\n",
    "        query_emb = embed_texts([query])\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb, axis=1, keepdims=True)\n",
    "        \n",
    "        # cosine similarity\n",
    "        # only need dot-product as the embeddings are already normalized\n",
    "        similarity = np.dot(query_emb, self.embeddings.T).flatten()\n",
    "        \n",
    "        topk_idxs = np.argpartition(similarity, -k)[-k:]\n",
    "        topk_idxs = sorted(topk_idxs, key=lambda x: similarity[x],\n",
    "                           reverse=True)\n",
    "        \n",
    "        return [self.texts[i] for i in topk_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a595edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.017000675201416016\n",
      "[\"The best joke you'll never hear\", 'Meet the parents', 'Hire The Pretty Blonde', 'Just one time I wanna see The Bachelor get a cold sore', 'What do you call a bald porcupine? Pointless!', 'pull my upvote', \"My life That's the joke.\", 'What do you call corn with a sense of humor? Laughing stalk', 'What do you call a bald porcupine? Pointless.', 'Velcro. What a rip off!']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = 'Laugh'\n",
    "with open('jokes.txt', 'r') as f:\n",
    "    jokes = [l.strip() for l in f.readlines()]\n",
    "embs = np.load('embeddings.npy')\n",
    "\n",
    "basic_rag = BasicEmbeddingsRAG(jokes, embs)\n",
    "\n",
    "start = time.time()\n",
    "nearest = basic_rag.get_nearest(query, k=10)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time: {end - start}')\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45f5c",
   "metadata": {},
   "source": [
    "### JokeGenerator Example\n",
    "`Query -> (Idea LM <-> WebSearch) -> Joke Idea -> (Joke LM <-> Joke DB) -> Joke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "with DSPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
